Documentation on what was worked on

[Diagram](https://lucid.app/lucidspark/2ff52c50-2500-4ee2-a7dd-ebf1d90b84be/edit?viewport_loc=-851%2C-3577%2C5191%2C2639%2C0_0&invitationId=inv_b17be3f2-adcc-492d-a712-b17c2a8c2aa1)

-----26/07/25-----

GOAL: Trying to plan a direction and general idea of how the app should work.

What we did:

    Set up Git repo
    Set up environment on VSCode

    Planned out the app system and direction

        --Core--

        claim extraction
        claim verifier

        --Addtional Features--

        Audio to txt --Add later on
        web browser extension

    Learning more about SpaCy.
    Trying to understand English sentance structures.

    Compressing sentences(Triplet Extraction) using spacy.

------27/07/25------

GOAL: Setting milestones, creating flow chart for each core features.

What we did:

    Worked on the pipeline structure.
    Set up Jira board.

    Made some progress on UML diagram.

------28/07/25------

GOAL: discuss and continue with flow chart and diagrams, start adding features

What we did:

    Decided to add an extra NER layer for more indepth classification of tokens. (updated diagram)
    new diagrams

Feature updates:

    TextCatergorizer custom component - John
    simple wikipedia scraper and sqlite save feature added -John
    pipeline_interface class -Foster

------29/07/25------

GOAL:

What we did:

    Scrapped pipeline interface class and started work on filter 1.

Feature updates:

    ClaimFilter1.py custom component - Foster

---
